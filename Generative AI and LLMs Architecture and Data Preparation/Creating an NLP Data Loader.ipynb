{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPoYrGof8PNRf2wgZWWH0Hi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip show torch\n","!pip show torchtext"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M4CHO3u2ZQCK","executionInfo":{"status":"ok","timestamp":1738247712700,"user_tz":-300,"elapsed":3024,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"11ea7a3a-c5fb-4422-c66b-3c954c2e543f"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: torch\n","Version: 2.5.1+cu124\n","Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n","Home-page: https://pytorch.org/\n","Author: PyTorch Team\n","Author-email: packages@pytorch.org\n","License: BSD-3-Clause\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: filelock, fsspec, jinja2, networkx, nvidia-cublas-cu12, nvidia-cuda-cupti-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-runtime-cu12, nvidia-cudnn-cu12, nvidia-cufft-cu12, nvidia-curand-cu12, nvidia-cusolver-cu12, nvidia-cusparse-cu12, nvidia-nccl-cu12, nvidia-nvjitlink-cu12, nvidia-nvtx-cu12, sympy, triton, typing-extensions\n","Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchvision\n","\u001b[33mWARNING: Package(s) not found: torchtext\u001b[0m\u001b[33m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install torchtext==0.15.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QtDTf7xrZVnS","executionInfo":{"status":"ok","timestamp":1738247871311,"user_tz":-300,"elapsed":148249,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"db7e2fe2-ed20-413e-c68f-3f19473a6af5"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchtext==0.15.2\n","  Downloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.4 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (2.32.3)\n","Collecting torch==2.0.1 (from torchtext==0.15.2)\n","  Downloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.2) (1.26.4)\n","Collecting torchdata==0.6.1 (from torchtext==0.15.2)\n","  Downloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.17.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1->torchtext==0.15.2) (3.1.5)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.0.0 (from torch==2.0.1->torchtext==0.15.2)\n","  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.1->torchtext==0.15.2) (2.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchtext==0.15.2) (0.45.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2) (3.31.4)\n","Collecting lit (from triton==2.0.0->torch==2.0.1->torchtext==0.15.2)\n","  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.2) (2024.12.14)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1->torchtext==0.15.2) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1->torchtext==0.15.2) (1.3.0)\n","Downloading torchtext-0.15.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.0.1-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m948.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchdata-0.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata, torchtext\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.1.0\n","    Uninstalling triton-3.1.0:\n","      Successfully uninstalled triton-3.1.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.5.1+cu124\n","    Uninstalling torch-2.5.1+cu124:\n","      Successfully uninstalled torch-2.5.1+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\n","torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 torchdata-0.6.1 torchtext-0.15.2 triton-2.0.0\n"]}]},{"cell_type":"code","source":["!pip show torch\n","!pip show torchtext"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ib43MqQkZZ0t","executionInfo":{"status":"ok","timestamp":1738247876708,"user_tz":-300,"elapsed":5409,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"77bf64cb-0550-435b-9a59-c6a835846b7a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: torch\n","Version: 2.0.1\n","Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n","Home-page: https://pytorch.org/\n","Author: PyTorch Team\n","Author-email: packages@pytorch.org\n","License: BSD-3\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: filelock, jinja2, networkx, nvidia-cublas-cu11, nvidia-cuda-cupti-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-runtime-cu11, nvidia-cudnn-cu11, nvidia-cufft-cu11, nvidia-curand-cu11, nvidia-cusolver-cu11, nvidia-cusparse-cu11, nvidia-nccl-cu11, nvidia-nvtx-cu11, sympy, triton, typing-extensions\n","Required-by: accelerate, fastai, peft, sentence-transformers, timm, torchaudio, torchdata, torchtext, torchvision, triton\n","Name: torchtext\n","Version: 0.15.2\n","Summary: Text utilities and datasets for PyTorch\n","Home-page: https://github.com/pytorch/text\n","Author: PyTorch core devs and James Bradbury\n","Author-email: jekbradbury@gmail.com\n","License: BSD\n","Location: /usr/local/lib/python3.11/dist-packages\n","Requires: numpy, requests, torch, torchdata, tqdm\n","Required-by: \n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ezAONMEY5tF","executionInfo":{"status":"ok","timestamp":1738247885344,"user_tz":-300,"elapsed":8644,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"740e1a0b-b49e-4452-aca2-fe7f43d5b1f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["0.15.2+cpu\n"]}],"source":["import torchtext\n","print(torchtext.__version__)"]},{"cell_type":"code","source":["import pandas as pd\n","from torch.utils.data import Dataset, DataLoader\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torchtext.datasets import multi30k, Multi30k\n","from typing import Iterable, List\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader\n","from torchdata.datapipes.iter import IterableWrapper, Mapper\n","import torchtext\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import numpy as np\n","import random"],"metadata":{"id":"dtu6MkS7p2t2","executionInfo":{"status":"ok","timestamp":1738253742867,"user_tz":-300,"elapsed":3514,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Sentences dataset\n","sentences = [\n","    \"Treat people kindly, especially those less powerful.\",\n","    \"Fame is unpredictable, Harry.\",\n","    \"Choices define us more than abilities.\",\n","    \"Right vs. easy – choose wisely.\",\n","    \"Youth can't understand age, but age shouldn't forget youth.\",\n","    \"You are awesome!\"\n","]\n","\n","#Custom dataset\n","class CustomDataset(Dataset):\n","    def __init__(self, sentences):\n","        self.sentences = sentences\n","\n","    def __len__(self):\n","      return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","      return self.sentences[idx]\n","\n","#Dataloader\n","dataloader = DataLoader(CustomDataset(sentences), batch_size=2, shuffle=True)\n","\n","#Display batches\n","for batch in dataloader:\n","  print(batch)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pSvwwo2DqEm7","executionInfo":{"status":"ok","timestamp":1738248724312,"user_tz":-300,"elapsed":396,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"d6346bee-155a-4db1-d956-bcc1f15b30d2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["[\"Youth can't understand age, but age shouldn't forget youth.\", 'Right vs. easy – choose wisely.']\n","['Treat people kindly, especially those less powerful.', 'Fame is unpredictable, Harry.']\n","['You are awesome!', 'Choices define us more than abilities.']\n"]}]},{"cell_type":"code","source":["sentences = [\n","    \"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\",\n","    \"Fame's a fickle friend, Harry.\",\n","    \"It is our choices, Harry, that show what we truly are, far more than our abilities.\",\n","    \"Soon we must all face the choice between what is right and what is easy.\",\n","    \"Youth can not know how age thinks and feels. But old men are guilty if they forget what it was to be young.\",\n","    \"You are awesome!\"\n","]\n","\n","# Define a custom data set\n","class CustomDataset(Dataset):\n","    def __init__(self, sentences, tokenizer, vocab):\n","        self.sentences = sentences\n","        self.tokenizer = tokenizer\n","        self.vocab = vocab\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        tokens = self.tokenizer(self.sentences[idx])\n","        # Convert tokens to tensor indices using vocab\n","        tensor_indices = [self.vocab[token] for token in tokens]\n","        return torch.tensor(tensor_indices)\n","\n","# Tokenizer\n","tokenizer = get_tokenizer(\"basic_english\")\n","\n","# Build vocabulary\n","vocab = build_vocab_from_iterator(map(tokenizer, sentences))\n","\n","# Create an instance of your custom data set\n","custom_dataset = CustomDataset(sentences, tokenizer, vocab)\n","\n","print(\"Custom Dataset Length:\", len(custom_dataset))\n","print(\"Sample Items:\")\n","for i in range(6):\n","    sample_item = custom_dataset[i]\n","    print(f\"Item {i + 1}: {sample_item}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VRZGVUQJspt9","executionInfo":{"status":"ok","timestamp":1738249695982,"user_tz":-300,"elapsed":379,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"cc0e528e-96d6-4591-98b3-bf126230d67e"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Custom Dataset Length: 6\n","Sample Items:\n","Item 1: tensor([11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n","        43, 61,  9, 44,  0, 14,  9, 33,  1])\n","Item 2: tensor([35,  6, 16,  3, 38, 40,  0,  8,  1])\n","Item 3: tensor([12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n","        21,  1])\n","Item 4: tensor([54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1])\n","Item 5: tensor([66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n","         2, 12, 64, 17, 26, 65,  1])\n","Item 6: tensor([19,  4, 25, 20])\n"]}]},{"cell_type":"code","source":["#Define the batch size\n","batch_size = 2\n","\n","# Create a data loader\n","dataloader = DataLoader(custom_dataset, batch_size, shuffle=True, collate_fn=pad_sequence)\n","\n","\n","# Iterate through the data loader\n","for batch in dataloader:\n","    print(batch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hrERlBqXwNiD","executionInfo":{"status":"ok","timestamp":1738250073775,"user_tz":-300,"elapsed":395,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"a5132b5a-7c1f-4424-cebe-76a6d327580e"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[19, 54],\n","        [ 4, 18],\n","        [25, 50],\n","        [20, 23],\n","        [ 0, 34],\n","        [ 0, 58],\n","        [ 0, 30],\n","        [ 0, 27],\n","        [ 0,  2],\n","        [ 0,  5],\n","        [ 0, 52],\n","        [ 0,  7],\n","        [ 0,  2],\n","        [ 0,  5],\n","        [ 0, 32],\n","        [ 0,  1]])\n","tensor([[66, 12],\n","        [29,  5],\n","        [14, 15],\n","        [13, 31],\n","        [10,  0],\n","        [22,  8],\n","        [60,  0],\n","        [ 7, 57],\n","        [37, 53],\n","        [ 1,  2],\n","        [28, 18],\n","        [51, 62],\n","        [48,  4],\n","        [ 4,  0],\n","        [42, 36],\n","        [11, 49],\n","        [59, 56],\n","        [39, 15],\n","        [ 2, 21],\n","        [12,  1],\n","        [64,  0],\n","        [17,  0],\n","        [26,  0],\n","        [65,  0],\n","        [ 1,  0]])\n","tensor([[35, 11],\n","        [ 6, 19],\n","        [16, 63],\n","        [ 3, 17],\n","        [38, 13],\n","        [40,  2],\n","        [ 0,  3],\n","        [ 8, 47],\n","        [ 1,  6],\n","        [ 0, 16],\n","        [ 0, 45],\n","        [ 0,  0],\n","        [ 0, 55],\n","        [ 0,  3],\n","        [ 0, 41],\n","        [ 0, 46],\n","        [ 0, 24],\n","        [ 0, 10],\n","        [ 0, 43],\n","        [ 0, 61],\n","        [ 0,  9],\n","        [ 0, 44],\n","        [ 0,  0],\n","        [ 0, 14],\n","        [ 0,  9],\n","        [ 0, 33],\n","        [ 0,  1]])\n"]}]},{"cell_type":"code","source":["# Create a custom collate function\n","\n","def collate_fn(batch):\n","  # Pad sequences within the batch to have equal lengths\n","  padded_batch = pad_sequence(batch, batch_first=True, padding_value=0)\n","  return padded_batch\n"],"metadata":{"id":"MghYZHp4xYce","executionInfo":{"status":"ok","timestamp":1738250340842,"user_tz":-300,"elapsed":372,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Create a data loader with the custom collate function with batch_first=True,\n","dataloader = DataLoader(custom_dataset, batch_size=batch_size, collate_fn=collate_fn)\n","\n","# Iterate through the data loader\n","for batch in dataloader:\n","    for row in batch:\n","        for idx in row:\n","          word = [vocab.get_itos()[idx] for idx in row]\n","        print(word)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GJcxo6eKy0ZH","executionInfo":{"status":"ok","timestamp":1738250538924,"user_tz":-300,"elapsed":382,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"22395eba-7f4c-4ccb-b0be-4c1742ed5605"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["['if', 'you', 'want', 'to', 'know', 'what', 'a', 'man', \"'\", 's', 'like', ',', 'take', 'a', 'good', 'look', 'at', 'how', 'he', 'treats', 'his', 'inferiors', ',', 'not', 'his', 'equals', '.']\n","['fame', \"'\", 's', 'a', 'fickle', 'friend', ',', 'harry', '.', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n","['it', 'is', 'our', 'choices', ',', 'harry', ',', 'that', 'show', 'what', 'we', 'truly', 'are', ',', 'far', 'more', 'than', 'our', 'abilities', '.']\n","['soon', 'we', 'must', 'all', 'face', 'the', 'choice', 'between', 'what', 'is', 'right', 'and', 'what', 'is', 'easy', '.', ',', ',', ',', ',']\n","['youth', 'can', 'not', 'know', 'how', 'age', 'thinks', 'and', 'feels', '.', 'but', 'old', 'men', 'are', 'guilty', 'if', 'they', 'forget', 'what', 'it', 'was', 'to', 'be', 'young', '.']\n","['you', 'are', 'awesome', '!', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n"]}]},{"cell_type":"code","source":["# Create a custom collate function\n","def collate_fn_bfFALSE(batch):\n","    # Pad sequences within the batch to have equal lengths\n","    padded_batch = pad_sequence(batch, padding_value=0)\n","    return padded_batch"],"metadata":{"id":"Xk_eHbG9zkqF","executionInfo":{"status":"ok","timestamp":1738250553639,"user_tz":-300,"elapsed":453,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["\n","\n","# Create a data loader with the custom collate function with batch_first=True,\n","dataloader_bfFALSE = DataLoader(custom_dataset, batch_size=batch_size, collate_fn=collate_fn_bfFALSE)\n","\n","# Iterate through the data loader\n","for seq in dataloader_bfFALSE:\n","    for row in seq:\n","        #print(row)\n","        words = [vocab.get_itos()[idx] for idx in row]\n","        print(words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bhsPKDghzoUn","executionInfo":{"status":"ok","timestamp":1738250559069,"user_tz":-300,"elapsed":404,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"6f8412b2-bad4-4fb9-cd78-ae17f3a3dc62"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["['if', 'fame']\n","['you', \"'\"]\n","['want', 's']\n","['to', 'a']\n","['know', 'fickle']\n","['what', 'friend']\n","['a', ',']\n","['man', 'harry']\n","[\"'\", '.']\n","['s', ',']\n","['like', ',']\n","[',', ',']\n","['take', ',']\n","['a', ',']\n","['good', ',']\n","['look', ',']\n","['at', ',']\n","['how', ',']\n","['he', ',']\n","['treats', ',']\n","['his', ',']\n","['inferiors', ',']\n","[',', ',']\n","['not', ',']\n","['his', ',']\n","['equals', ',']\n","['.', ',']\n","['it', 'soon']\n","['is', 'we']\n","['our', 'must']\n","['choices', 'all']\n","[',', 'face']\n","['harry', 'the']\n","[',', 'choice']\n","['that', 'between']\n","['show', 'what']\n","['what', 'is']\n","['we', 'right']\n","['truly', 'and']\n","['are', 'what']\n","[',', 'is']\n","['far', 'easy']\n","['more', '.']\n","['than', ',']\n","['our', ',']\n","['abilities', ',']\n","['.', ',']\n","['youth', 'you']\n","['can', 'are']\n","['not', 'awesome']\n","['know', '!']\n","['how', ',']\n","['age', ',']\n","['thinks', ',']\n","['and', ',']\n","['feels', ',']\n","['.', ',']\n","['but', ',']\n","['old', ',']\n","['men', ',']\n","['are', ',']\n","['guilty', ',']\n","['if', ',']\n","['they', ',']\n","['forget', ',']\n","['what', ',']\n","['it', ',']\n","['was', ',']\n","['to', ',']\n","['be', ',']\n","['young', ',']\n","['.', ',']\n"]}]},{"cell_type":"code","source":["# Iterate through the data loader with batch_first = TRUE\n","for batch in dataloader:\n","    print(batch)\n","    print(\"Length of sequences in the batch:\",batch.shape[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nPc4xaDgzppy","executionInfo":{"status":"ok","timestamp":1738250651131,"user_tz":-300,"elapsed":421,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"72d9ba45-5837-4551-c2d6-0157d9822c94"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[11, 19, 63, 17, 13,  2,  3, 47,  6, 16, 45,  0, 55,  3, 41, 46, 24, 10,\n","         43, 61,  9, 44,  0, 14,  9, 33,  1],\n","        [35,  6, 16,  3, 38, 40,  0,  8,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0,  0,  0]])\n","Length of sequences in the batch: 27\n","tensor([[12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n","         21,  1],\n","        [54, 18, 50, 23, 34, 58, 30, 27,  2,  5, 52,  7,  2,  5, 32,  1,  0,  0,\n","          0,  0]])\n","Length of sequences in the batch: 20\n","tensor([[66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n","          2, 12, 64, 17, 26, 65,  1],\n","        [19,  4, 25, 20,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0,  0,  0,  0]])\n","Length of sequences in the batch: 25\n"]}]},{"cell_type":"code","source":["#Define the custom data set\n","class CustomDataset(Dataset):\n","    def __init__(self, sentences):\n","        self.sentences = sentences\n","\n","    def __len__(self):\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        return self.sentences[idx]\n",""],"metadata":{"id":"Zu-iz74O0AHa","executionInfo":{"status":"ok","timestamp":1738250837345,"user_tz":-300,"elapsed":391,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["custom_dataset=CustomDataset(sentences)"],"metadata":{"id":"irF-OhZp0tmg","executionInfo":{"status":"ok","timestamp":1738250838311,"user_tz":-300,"elapsed":5,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["custom_dataset[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"hZpJxQ9C0t3w","executionInfo":{"status":"ok","timestamp":1738250850520,"user_tz":-300,"elapsed":437,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"2f44d018-8bd6-4b56-b92f-48b43cd6b773"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"If you want to know what a man's like, take a good look at how he treats his inferiors, not his equals.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["def collate_fn(batch):\n","  # Tokenize each sample in the batch using the specified tokenizer\n","  tensor_batch = []\n","  for sample in batch:\n","    tokens = tokenizer(sample)\n","    # Convert tokens to vocabulary indices and create a tensor for each sample\n","    tensor_batch.append(torch.tensor([vocab[token] for token in tokens]))\n","\n","    # Pad sequences within the batch to have equal lengths using pad_sequence\n","    # batch_first=True ensures that the tensors have shape (batch_size, max_sequence_length)\n","    padded_batch = pad_sequence(tensor_batch, batch_first=True, padding_value=0)\n","    return padded_batch"],"metadata":{"id":"NkhtK19b0wmH","executionInfo":{"status":"ok","timestamp":1738251097953,"user_tz":-300,"elapsed":367,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Create a data loader for the custom dataset\n","dataloader = DataLoader(\n","    dataset=custom_dataset,   # Custom PyTorch Dataset containing your data\n","    batch_size=batch_size,     # Number of samples in each mini-batch\n","    shuffle=True,              # Shuffle the data at the beginning of each epoch\n","    collate_fn=collate_fn      # Custom collate function for processing batches\n",")"],"metadata":{"id":"-59FcPTB1tOk","executionInfo":{"status":"ok","timestamp":1738251182014,"user_tz":-300,"elapsed":443,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["for batch in dataloader:\n","    print(batch)\n","    print(\"Length of sequences in the batch:\",batch.shape[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrvmlnsH2BvL","executionInfo":{"status":"ok","timestamp":1738251231150,"user_tz":-300,"elapsed":393,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"48a862bb-ec6e-40b6-c7c5-26f876b6875d"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[12,  5, 15, 31,  0,  8,  0, 57, 53,  2, 18, 62,  4,  0, 36, 49, 56, 15,\n","         21,  1]])\n","Length of sequences in the batch: 20\n","tensor([[35,  6, 16,  3, 38, 40,  0,  8,  1]])\n","Length of sequences in the batch: 9\n","tensor([[66, 29, 14, 13, 10, 22, 60,  7, 37,  1, 28, 51, 48,  4, 42, 11, 59, 39,\n","          2, 12, 64, 17, 26, 65,  1]])\n","Length of sequences in the batch: 25\n"]}]},{"cell_type":"markdown","source":["# Exercise\n","Create a data loader with a collate function that processes batches of French text (provided below). Sort the data set on sequences length. Then tokenize, numericalize and pad the sequences. Sorting the sequences will minimize the number of <PAD>tokens added to the sequences, which enhances the model's performance. Prepare the data in batches of size 4 and print them."],"metadata":{"id":"qLvRQh_v2RMr"}},{"cell_type":"code","source":["!python -m spacy download fr_core_news_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"t3RoHuWD5fVb","executionInfo":{"status":"ok","timestamp":1738252101171,"user_tz":-300,"elapsed":11016,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"3eefd1e5-afdf-470c-bfa5-881883cafe05"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fr-core-news-sm==3.7.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.7.0/fr_core_news_sm-3.7.0-py3-none-any.whl (16.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from fr-core-news-sm==3.7.0) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.15.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.1.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2024.12.14)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->fr-core-news-sm==3.7.0) (0.1.2)\n","Installing collected packages: fr-core-news-sm\n","Successfully installed fr-core-news-sm-3.7.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('fr_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["corpus = [\n","    \"Ceci est une phrase.\",\n","    \"C'est un autre exemple de phrase.\",\n","    \"Voici une troisième phrase.\",\n","    \"Il fait beau aujourd'hui.\",\n","    \"J'aime beaucoup la cuisine française.\",\n","    \"Quel est ton plat préféré ?\",\n","    \"Je t'adore.\",\n","    \"Bon appétit !\",\n","    \"Je suis en train d'apprendre le français.\",\n","    \"Nous devons partir tôt demain matin.\",\n","    \"Je suis heureux.\",\n","    \"Le film était vraiment captivant !\",\n","    \"Je suis là.\",\n","    \"Je ne sais pas.\",\n","    \"Je suis fatigué après une longue journée de travail.\",\n","    \"Est-ce que tu as des projets pour le week-end ?\",\n","    \"Je vais chez le médecin cet après-midi.\",\n","    \"La musique adoucit les mœurs.\",\n","    \"Je dois acheter du pain et du lait.\",\n","    \"Il y a beaucoup de monde dans cette ville.\",\n","    \"Merci beaucoup !\",\n","    \"Au revoir !\",\n","    \"Je suis ravi de vous rencontrer enfin !\",\n","    \"Les vacances sont toujours trop courtes.\",\n","    \"Je suis en retard.\",\n","    \"Félicitations pour ton nouveau travail !\",\n","    \"Je suis désolé, je ne peux pas venir à la réunion.\",\n","    \"À quelle heure est le prochain train ?\",\n","    \"Bonjour !\",\n","    \"C'est génial !\"\n","]\n","\n","def collate_fn_fr(batch):\n","    # Pad sequences within the batch to have equal lengths\n","    tensor_batch=[]\n","    for sample in batch:\n","        tokens = tokenizer(sample)\n","        tensor_batch.append(torch.tensor([vocab[token] for token in tokens]))\n","\n","    padded_batch = pad_sequence(tensor_batch,batch_first=True)\n","    return padded_batch\n","\n","# Build tokenizer\n","tokenizer = get_tokenizer('spacy', language='fr_core_news_sm')\n","\n","# Build vocabulary\n","vocab = build_vocab_from_iterator(map(tokenizer, corpus))\n","\n","# Sort sentences based on their length\n","sorted_data = sorted(corpus, key=lambda x: len(tokenizer(x)))\n","#print(sorted_data)\n","dataloader = DataLoader(sorted_data, batch_size=4, shuffle=False, collate_fn=collate_fn_fr)\n","\n","for batch in dataloader:\n","    print(batch)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSR7C9wN2NjA","executionInfo":{"status":"ok","timestamp":1738252182722,"user_tz":-300,"elapsed":2384,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"368078de-c889-4bc7-9329-7060c0bb94f7"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 27,   2,   0],\n","        [ 26,  45,   2],\n","        [ 35,   8,   2],\n","        [ 25, 101,   2]])\n","tensor([[  1, 105,  41,   0],\n","        [  1,   3,  76,   0],\n","        [  1,   3,  82,   0],\n","        [ 11,   4,  74,   2]])\n","tensor([[ 28,   4,  10,   9,   0],\n","        [ 38,  10, 107,   9,   0],\n","        [ 12,  69,  51,  49,   0],\n","        [  1,  16, 103,  17,   0]])\n","tensor([[  1,   3,  14, 100,   0,   0],\n","        [ 37,   4,  19,  92,  95,   7],\n","        [ 33,  71, 122, 117,  52,   2],\n","        [ 32,  85,  42,  80,  87,   0]])\n","tensor([[ 30,  18,  19,  88,  21,   2,   0],\n","        [ 31,  43,   8,  15,  57,  73,   0],\n","        [ 36,  62,  90, 110,  60,  83,   0],\n","        [ 34, 112, 104, 106, 108,  56,   0]])\n","tensor([[ 11,   4, 111,  50,  68,   5,   9,   0],\n","        [  1, 113,  55,   6,  86,  53,  47,   0],\n","        [  1,   3,  98,   5, 116,  99,  66,   2],\n","        [120,  97,  75,   4,   6,  93,  20,   7]])\n","tensor([[  1,   3,  14,  20,  58,  44,   6,  72,   0,   0],\n","        [  1,  63,  40,  13,  89,  67,  13,  79,   0,   0],\n","        [  1,   3,  70,  46,  10,  81,  78,   5,  21,   0],\n","        [ 12, 119,  39,   8,   5,  84,  59,  54, 115,   0]])\n","tensor([[ 29,  24,  96, 109,  48,  61,  94,  18,   6, 118,  23,  65,   7],\n","        [  1,   3,  64,  22,  77,  16,  91,  17, 114, 121,  15, 102,   0]])\n"]}]},{"cell_type":"markdown","source":["# Data loader for German-English translation task\n","This section sets the stage for German-English machine translation using the torchtext and spaCy libraries. It adjusts data set URLs for the Multi30k data set, configures tokenizers for both languages, and establishes vocabularies with special tokens. This foundation is crucial for building and training effective translation models.\n","\n","Data set configuration and language definition\n","\n","Default URLs for the Multi30k dataset are modified to fix broken links.\n","Source (de for German) and target (en for English) languages are defined.\n","Tokenizer setup\n","\n","Tokenizers for both languages are set up using spaCy.\n","Token generation\n","\n","A helper function, yield_tokens, is created to generate tokens from the data set\n","Special symbols\n","\n","Special symbols (e.g., <unk>, <pad>) and their indices are defined.\n","Vocabulary building\n","\n","Vocabularies for both source and target languages are built from the training data of the Multi30k dataset converting tokens to unique indices (numbers)\n","Default token handling\n","\n","A default index (UNK_IDX) is set for tokens not found in the vocabulary.\n","# Translation data set\n","In this section, you fetch a language translation data set called Multi30k. You will modify its default training and validation URLs, and then retrieve and print the first pair of German-English sentences from the training set. First, you will override the default URLs:"],"metadata":{"id":"dbkb0aXF7Gq-"}},{"cell_type":"code","source":["!pip install portalocker"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"UZ9xluam8r9Q","executionInfo":{"status":"ok","timestamp":1738252933526,"user_tz":-300,"elapsed":3490,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"5eba27c3-8d8d-4c48-ced8-68dab26382f3"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting portalocker\n","  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n","Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n","Installing collected packages: portalocker\n","Successfully installed portalocker-3.1.1\n"]}]},{"cell_type":"code","source":["num_workers: 0 #This can be increased if you want parallel execution"],"metadata":{"id":"pIqRyYEb_Vrl","executionInfo":{"status":"ok","timestamp":1738253626718,"user_tz":-300,"elapsed":417,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade torchtext==0.15.1  # Downgrading to a previous version."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"collapsed":true,"id":"qcNlzqZG_ZwQ","executionInfo":{"status":"ok","timestamp":1738253712182,"user_tz":-300,"elapsed":71296,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"a5306423-feca-418c-f40d-1e6110a94633"},"execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchtext==0.15.1\n","  Downloading torchtext-0.15.1-cp311-cp311-manylinux1_x86_64.whl.metadata (7.4 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (2.32.3)\n","Collecting torch==2.0.0 (from torchtext==0.15.1)\n","  Downloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.15.1) (1.26.4)\n","Collecting torchdata==0.6.0 (from torchtext==0.15.1)\n","  Downloading torchdata-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (892 bytes)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.17.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (3.1.5)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.99)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.101)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.10.3.66)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (10.2.10.91)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.4.0.1)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.4.91)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.14.3)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (11.7.91)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0->torchtext==0.15.1) (2.0.0)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.6.0->torchtext==0.15.1) (2.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (75.1.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchtext==0.15.1) (0.45.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (3.31.4)\n","Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0->torchtext==0.15.1) (18.1.8)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.15.1) (2024.12.14)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0->torchtext==0.15.1) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0->torchtext==0.15.1) (1.3.0)\n","Downloading torchtext-0.15.1-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.0.0-cp311-cp311-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m766.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchdata-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch, torchdata, torchtext\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.0.1\n","    Uninstalling torch-2.0.1:\n","      Successfully uninstalled torch-2.0.1\n","  Attempting uninstall: torchdata\n","    Found existing installation: torchdata 0.6.1\n","    Uninstalling torchdata-0.6.1:\n","      Successfully uninstalled torchdata-0.6.1\n","  Attempting uninstall: torchtext\n","    Found existing installation: torchtext 0.15.2\n","    Uninstalling torchtext-0.15.2:\n","      Successfully uninstalled torchtext-0.15.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\n","torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-2.0.0 torchdata-0.6.0 torchtext-0.15.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["nvfuser","torch","torchdata","torchtext"]},"id":"7d3528ad589744c39deb74dbfe352077"}},"metadata":{}}]},{"cell_type":"code","source":["# Import necessary libraries\n","from torchtext.datasets import Multi30k\n","\n","# Set source and target languages\n","SRC_LANGUAGE = 'de'\n","TGT_LANGUAGE = 'en'\n","\n","# Adjust data set URLs (if necessary)\n","multi30k.URL[\"train\"] = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/training.tar.gz\"\n","multi30k.URL[\"valid\"] = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-AI0205EN-SkillsNetwork/validation.tar.gz\"\n","\n","for n in range(5):\n","    # Re-initialize the data set generator before each loop iteration\n","    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","    data_set = iter(train_iter)\n","    # Getting the next pair of source and target sentences from the training data set\n","    src, tgt = next(data_set)\n","\n","    # Printing the source (German) and target (English) sentences\n","    print(f\"sample {str(n+1)}\")\n","    print(f\"Source ({SRC_LANGUAGE}): {src}\\nTarget ({TGT_LANGUAGE}): {tgt}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IwlOQj_l8_8H","executionInfo":{"status":"ok","timestamp":1738253756899,"user_tz":-300,"elapsed":781,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"ffb8447b-5565-41c1-a770-d56e449d8a3a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["sample 1\n","Source (de): Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n","Target (en): Two young, White males are outside near many bushes.\n","sample 2\n","Source (de): Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n","Target (en): Two young, White males are outside near many bushes.\n","sample 3\n","Source (de): Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n","Target (en): Two young, White males are outside near many bushes.\n","sample 4\n","Source (de): Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n","Target (en): Two young, White males are outside near many bushes.\n","sample 5\n","Source (de): Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.\n","Target (en): Two young, White males are outside near many bushes.\n"]}]},{"cell_type":"code","source":["german, english = next(data_set)\n","print(f\"Source German ({SRC_LANGUAGE}): {german}\\nTarget English  ({TGT_LANGUAGE}): { english }\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hKdKM-Ee-bVj","executionInfo":{"status":"ok","timestamp":1738253791582,"user_tz":-300,"elapsed":394,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"e6f719a4-d91c-4f44-c63c-8913a69dd226"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Source German (de): Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\n","Target English  (en): Several men in hard hats are operating a giant pulley system.\n"]}]},{"cell_type":"code","source":["from torchtext.data.utils import get_tokenizer"],"metadata":{"id":"cI5p9-OD_-vS","executionInfo":{"status":"ok","timestamp":1738253847312,"user_tz":-300,"elapsed":405,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!python -m spacy download de_core_news_sm\n","!python -m spacy download en_core_web_sm"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"w3kbpjcLAZhm","executionInfo":{"status":"ok","timestamp":1738253923014,"user_tz":-300,"elapsed":21593,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"f74fd7b3-c619-41d8-e3ec-9fbc3101f9fc"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting de-core-news-sm==3.7.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from de-core-news-sm==3.7.0) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.15.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.12.14)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.2)\n","Installing collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-3.7.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('de_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n","Collecting en-core-web-sm==3.7.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.12)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.11)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.15.1)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.67.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.5.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.12.14)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n","Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.17.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["# Making a placeholder dict to store both tokenizers\n","token_transform = {}\n","\n","token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n","token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')"],"metadata":{"id":"dElzUzHMAHVa","executionInfo":{"status":"ok","timestamp":1738253935150,"user_tz":-300,"elapsed":4184,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["token_transform['de'](german)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SJ-6IiNzATis","executionInfo":{"status":"ok","timestamp":1738254054705,"user_tz":-300,"elapsed":463,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"a390b9d1-4b49-46af-9bfb-092648242a8a"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Mehrere',\n"," 'Männer',\n"," 'mit',\n"," 'Schutzhelmen',\n"," 'bedienen',\n"," 'ein',\n"," 'Antriebsradsystem',\n"," '.']"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["token_transform['en'](english)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rj71qk0jA84w","executionInfo":{"status":"ok","timestamp":1738254063516,"user_tz":-300,"elapsed":471,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"24cfdd6f-585b-41fd-c4e3-3f17473a5915"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Several',\n"," 'men',\n"," 'in',\n"," 'hard',\n"," 'hats',\n"," 'are',\n"," 'operating',\n"," 'a',\n"," 'giant',\n"," 'pulley',\n"," 'system',\n"," '.']"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Define special symbols and indices\n","UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0,1,2,3\n","# Make sure the tokens are in order of their indices to properly insert them in vocab\n","special_symbols = ['<unk>','<pad>','<bos>','<eos>']"],"metadata":{"id":"DPkMAoeCA_hG","executionInfo":{"status":"ok","timestamp":1738254369479,"user_tz":-300,"elapsed":416,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["#place holder dict for 'en' and 'de' vocab transforms\n","vocab_transform = {}"],"metadata":{"id":"TJ5R7FCPCL50","executionInfo":{"status":"ok","timestamp":1738254416998,"user_tz":-300,"elapsed":434,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n","    # Define a mapping to associate the source and target languages\n","    # with their respective positions in the data samples.\n","    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n","\n","    # Iterate over each data sample in the provided dataset iterator\n","    for data_sample in data_iter:\n","        # Tokenize the data sample corresponding to the specified language\n","        # and yield the resulting tokens.\n","        yield token_transform[language](data_sample[language_index[language]])"],"metadata":{"id":"jBrRwKSACXhU","executionInfo":{"status":"ok","timestamp":1738254740279,"user_tz":-300,"elapsed":418,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    train_iterator = Multi30k(split=\"train\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","    sorted_dataset = sorted(train_iterator, key=lambda x : len(x[0].split()))\n","    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(sorted_dataset,ln),\n","                                                    min_freq=1,\n","                                                    specials=special_symbols,\n","                                                    special_first=True)\n","\n"],"metadata":{"id":"BD-AIPjeDma8","executionInfo":{"status":"ok","timestamp":1738255314621,"user_tz":-300,"elapsed":5464,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n","for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    vocab_transform[ln].set_default_index(UNK_IDX)"],"metadata":{"id":"Diy13TsZFhUS","executionInfo":{"status":"ok","timestamp":1738255424680,"user_tz":-300,"elapsed":355,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["seq_en=vocab_transform['en'](token_transform['en'](english))\n","print(f\"English text string: {english}\\n English sequence: {seq_en}\")\n","\n","seq_de=vocab_transform['de'](token_transform['de'](german))\n","print(f\"German text string: {german}\\n German sequence: {seq_de}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E62lzFgXGNkB","executionInfo":{"status":"ok","timestamp":1738255463334,"user_tz":-300,"elapsed":358,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"bfefb616-f8ef-420e-a12c-eee26dd2fc69"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["English text string: Several men in hard hats are operating a giant pulley system.\n"," English sequence: [165, 36, 7, 335, 287, 17, 1224, 4, 758, 4496, 2957, 5]\n","German text string: Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.\n"," German sequence: [84, 31, 10, 847, 2208, 15, 8268, 4]\n"]}]},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"AEASXQl-GW_W","executionInfo":{"status":"ok","timestamp":1738256003744,"user_tz":-300,"elapsed":365,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# function to add BOS/EOS, flip source sentence and create tensor for input sequence indices\n","def tensor_transform_s(token_ids: List[int]):\n","    return torch.cat((torch.tensor([BOS_IDX]),\n","                      torch.flip(torch.tensor(token_ids), dims=(0,)),\n","                      torch.tensor([EOS_IDX])))\n","\n","# function to add BOS/EOS and create tensor for input sequence indices\n","def tensor_transform_t(token_ids: List[int]):\n","    return torch.cat((torch.tensor([BOS_IDX]),\n","                      torch.tensor(token_ids),\n","                      torch.tensor([EOS_IDX])))"],"metadata":{"id":"9_MlpIvAGo-8","executionInfo":{"status":"ok","timestamp":1738256341807,"user_tz":-300,"elapsed":454,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["seq_en=tensor_transform_s(seq_en)\n","seq_en"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hSKN4sUjJMIO","executionInfo":{"status":"ok","timestamp":1738256343165,"user_tz":-300,"elapsed":5,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"52838bb1-5c53-48f0-9352-04f1decf959a"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([   2,    5, 2957, 4496,  758,    4, 1224,   17,  287,  335,    7,   36,\n","         165,    3])"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["seq_de=tensor_transform_t(seq_de)\n","seq_de"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bdx-Fp-AJY4L","executionInfo":{"status":"ok","timestamp":1738256343631,"user_tz":-300,"elapsed":4,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"128b4054-d56f-4e65-a0e3-a6619b579437"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([   2,   84,   31,   10,  847, 2208,   15, 8268,    4,    3])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["def sequential_transforms(*transforms):\n","    def func(txt_input):\n","        for transform in transforms:\n","            txt_input = transform(txt_input)\n","        # Return the transformed text after applying all transforms\n","        return txt_input\n","    return func # Return the inner function 'func'\n","\n","# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n","\n","text_transform = {}\n","\n","text_transform[SRC_LANGUAGE] = sequential_transforms(token_transform[SRC_LANGUAGE], #Tokenization\n","                                                     vocab_transform[SRC_LANGUAGE], #Numericalization\n","                                                     tensor_transform_s)  # Add BOS/EOS and create tensor\n","\n","text_transform[TGT_LANGUAGE] = sequential_transforms(token_transform[TGT_LANGUAGE], #Tokenization\n","                                                     vocab_transform[TGT_LANGUAGE], #Numericalization\n","                                                     tensor_transform_t)  # Add BOS/EOS and create tensor\n"],"metadata":{"id":"Q5BJc9YkJt6_","executionInfo":{"status":"ok","timestamp":1738257827386,"user_tz":-300,"elapsed":374,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# function to collate data samples into batch tensors\n","def collate_fn(batch):\n","    src_batch, tgt_batch = [], []\n","    for src_sample, tgt_sample in batch:\n","        src_sequences = text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\"))\n","        src_sequences = torch.tensor(src_sequences, dtype=torch.int64)\n","        tgt_sequences = text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\"))\n","        tgt_sequences = torch.tensor(tgt_sequences, dtype=torch.int64)\n","        src_batch.append(src_sequences)\n","        tgt_batch.append(tgt_sequences)\n","\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX,batch_first=True)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX,batch_first=True)\n","\n","    return src_batch.to(device), tgt_batch.to(device)\n"],"metadata":{"id":"ymB8vR_AMxrl","executionInfo":{"status":"ok","timestamp":1738257829170,"user_tz":-300,"elapsed":499,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 4\n","\n","train_iterator = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","sorted_train_iterator = sorted(train_iterator, key=lambda x: len(x[0].split()))\n","train_dataloader = DataLoader(sorted_train_iterator, batch_size=BATCH_SIZE, collate_fn=collate_fn,drop_last=True)\n","\n","valid_iterator = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","sorted_valid_dataloader = sorted(valid_iterator, key=lambda x: len(x[0].split()))\n","valid_dataloader = DataLoader(sorted_valid_dataloader, batch_size=BATCH_SIZE, collate_fn=collate_fn,drop_last=True)\n","\n","\n","src, trg = next(iter(train_dataloader))\n","src,trg"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bxK9_6S2O8ZN","executionInfo":{"status":"ok","timestamp":1738257830183,"user_tz":-300,"elapsed":511,"user":{"displayName":"Ali Arslan Khan","userId":"07352138272512093390"}},"outputId":"df851f25-69d5-4e91-be94-9891afb58990"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-38-7923683dec91>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  src_sequences = torch.tensor(src_sequences, dtype=torch.int64)\n","<ipython-input-38-7923683dec91>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  tgt_sequences = torch.tensor(tgt_sequences, dtype=torch.int64)\n"]},{"output_type":"execute_result","data":{"text/plain":["(tensor([[    2,     3,     1,     1,     1],\n","         [    2,  5510,     3,     1,     1],\n","         [    2,  5510,     3,     1,     1],\n","         [    2,  1701,     8, 12642,     3]]),\n"," tensor([[   2,    3,    1,    1,    1,    1,    1,    1,    1,    1,    1],\n","         [   2, 6650, 4623,  259,  172, 9953,  115,  692, 3428,    5,    3],\n","         [   2,  216,  110, 3913, 1650, 3823,   71, 2808, 2187,    5,    3],\n","         [   2,    6, 3398,  202,  109,   37,    3,    1,    1,    1,    1]]))"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":[],"metadata":{"id":"o5ExcoNEPB-F"},"execution_count":null,"outputs":[]}]}